{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Data Sources\n",
    "\n",
    "1. Google Trends API\n",
    "2. Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Features\n",
    "1. term\t\n",
    "2. current_popularity\t\n",
    "3. change_3mo\t\n",
    "4. change_6mo\t\n",
    "5. change_9mo\t\n",
    "6. change_12mo\t\n",
    "7. change_24mo\t\n",
    "8. popularity_2y\t\n",
    "9. sentiment\n",
    "10. subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visulizations to make...\n",
    "1. Sentiment PDF\n",
    "2. popularity and predicted popularity\n",
    "\n",
    "# Features to add...\n",
    "1. sentiment standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and instantiations\n",
    "from pytrends.request import TrendReq\n",
    "import tweepy\n",
    "from statsmodels.tsa import ar_model, stattools, arima_model\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from potosnail import Stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def GetReport(keywords, span='today 5-y', geo='', quiet=True):\n",
    "    '''observe a search term's popularity in the past 5 years'''\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    pytrends.build_payload(keywords, cat=0, timeframe=span, geo=geo, gprop='')\n",
    "    ts = pytrends.interest_over_time().drop(['isPartial'], axis='columns')\n",
    "    if quiet == False:\n",
    "        print(ts.plot())\n",
    "    return ts\n",
    "\n",
    "def AnalyzeTwitter(keyword):\n",
    "    '''find the average sentimental value and subjectivity of a given search term'''\n",
    "    c1 = 'aHXduTrDkva3ItY52tUtYVPvA'\n",
    "    c2 = 'Qs6d4oNT3zXxDqOhita7IG07CfAJGceoqIs1sGuA4OURlbLP6d'\n",
    "    a1 = '1181578611171762177-sGQaj7E9fpWi2aEB3MfWL4nTRovXYk'\n",
    "    a2 = 'wa77yBJZJSOKOAzdaJYDruc9U1HrGhzyDhWgKvSQpm2hv'\n",
    "    auth = tweepy.OAuthHandler(c1, c2)\n",
    "    auth.set_access_token(a1, a2)\n",
    "    api = tweepy.API(auth)\n",
    "    topic = api.search(keyword)\n",
    "    sent = 0\n",
    "    sub = 0\n",
    "    sents = []\n",
    "    for i in range(len(topic)):\n",
    "        tweet = topic[i]._json['text'].replace('@', '')\n",
    "        blob = TextBlob(tweet)\n",
    "        sents.append(blob.sentiment[0])\n",
    "        sent += blob.sentiment[0]/len(topic)\n",
    "        sub += blob.sentiment[1]/len(topic)\n",
    "    return sent, sub, sents\n",
    "\n",
    "def Collect(keyword, quiet=True):\n",
    "    '''tells us how popularity for a given search term is expected to change'''\n",
    "    row = {}\n",
    "    ts = GetReport([keyword])\n",
    "    row['term'] = keyword\n",
    "    model = ar_model.AutoReg(ts, lags=4).fit()\n",
    "    pred = model.predict(start=260, end=356)\n",
    "    current_popularity = np.array(ts)[-1][0]\n",
    "    row['current_popularity'] =  current_popularity\n",
    "    row['change_3mo'] = '{}%'.format(round(((pred[11] - current_popularity) / current_popularity) * 100, 1))\n",
    "    row['change_6mo'] = '{}%'.format(round(((pred[23] - current_popularity) / current_popularity) * 100, 1))\n",
    "    row['change_9mo'] = '{}%'.format(round(((pred[35] - current_popularity) / current_popularity) * 100, 1))\n",
    "    row['change_12mo'] = '{}%'.format(round(((pred[47] - current_popularity) / current_popularity) * 100, 1))\n",
    "    row['change_24mo'] = '{}%'.format(round(((pred[95] - current_popularity) / current_popularity) * 100, 1))\n",
    "    row['popularity_2y'] = round((((pred[95] - current_popularity) / current_popularity) + 1) * current_popularity)\n",
    "    estimated_reach = None\n",
    "    estimated_clicks = None\n",
    "    sentiment, subjectivity, sentiments = AnalyzeTwitter(keyword)\n",
    "    row['sentiment'] = round(sentiment, 2)\n",
    "    row['subjectivity'] = round(subjectivity, 2)\n",
    "    row['sentiments_std'] = round(np.std(sentiments), 2)\n",
    "    if quiet == True:\n",
    "        return row\n",
    "    else:\n",
    "        ts['date'] = ts.index \n",
    "        pred2 = pd.DataFrame(pred)\n",
    "        pred2.columns = [keyword]\n",
    "        pred2['date'] = pred.index\n",
    "        total = pd.concat([ts, pred2])\n",
    "        return total, row\n",
    "\n",
    "def CollectLoop(terms_list):\n",
    "    '''tells us how popularity for a given list of search terms are expected to change'''\n",
    "    df = pd.DataFrame(Collect(terms_list[0]), index=[0])\n",
    "    for term in terms_list[1:]:\n",
    "        temp = pd.DataFrame(Collect(term), index=[0])\n",
    "        df = pd.concat([df, temp])\n",
    "    return df.reset_index().drop(['index'], axis='columns')\n",
    "\n",
    "def PlotOne(keyword):\n",
    "    '''the output a user gets when looking at one term'''\n",
    "    ts, results = Collect(keyword, quiet=False)\n",
    "    subj = results['subjectivity']\n",
    "    obj = 1 - subj\n",
    "    X = ['%subjective', '%objective']\n",
    "    y = [subj, obj]\n",
    "    X2 = ['sentiment']\n",
    "    y2 = results['sentiment']\n",
    "    if results['popularity_2y'] > results['current_popularity']:\n",
    "        future = 'increase'\n",
    "    else:\n",
    "        future = 'decrease'\n",
    "    fig = go.Figure(go.Indicator(\n",
    "    domain = {'x': [0, 1], 'y': [0, 1]},\n",
    "    value = results['sentiment'],\n",
    "    mode = \"gauge+number\",\n",
    "    title = {'text': \"Sentiment of '{}' based on tweets\".format(keyword)},\n",
    "    gauge = {'axis': {'range': [-1, 1]},\n",
    "             'steps' : [\n",
    "                 {'range': [-1, 0], 'color': \"red\"},\n",
    "                 {'range': [0, 1], 'color': \"lightgreen\"}]}))\n",
    "    fig.show()\n",
    "    fig = go.Figure(go.Indicator(\n",
    "    domain = {'x': [0, 1], 'y': [0, 1]},\n",
    "    value = results['subjectivity'],\n",
    "    mode = \"gauge+number\",\n",
    "    title = {'text': \"Subjectivity of '{}' based on tweets\".format(keyword)},\n",
    "    gauge = {'axis': {'range': [0, 1]},\n",
    "             'steps' : [\n",
    "                 {'range': [0, 0.5], 'color': \"yellow\"},\n",
    "                 {'range': [0.5, 1], 'color': \"blue\"}]}))\n",
    "    fig.show()\n",
    "    fig = px.line(ts, x='date', y=keyword, range_y=[0, 100])\n",
    "    fig.show()\n",
    "    \n",
    "def PlotMany(keywords):\n",
    "    '''the output a user gets when looking at multiple terms'''\n",
    "    ts = GetReport(keywords)\n",
    "    results = CollectLoop(keywords)\n",
    "    fig = px.bar(results, x='term', y='popularity_2y', \n",
    "                 color='current_popularity', title='Predicted Search Popularity in the next 2 years', range_y=[0, 100])\n",
    "    fig.show()\n",
    "    sentiments = []\n",
    "    stds = []\n",
    "    for keyword in keywords:\n",
    "        sentiment , _, sents = AnalyzeTwitter(keyword)\n",
    "        sentiments.append(sentiment)\n",
    "        stds.append(np.std(sents))\n",
    "    twitter = {'term': products, 'sentiment': sentiments, 'std': stds}\n",
    "    df = pd.DataFrame(twitter)\n",
    "    fig = px.bar(df, x='term', y='sentiment', \n",
    "                     color='std', title='Twitter sentiment', range_y=[-1, 1])\n",
    "    fig.show()\n",
    "    results['new'] = results['change_24mo'].apply(lambda x: float(x[:-1]))\n",
    "    best = results.loc[results['new']==max(results['new'])]['term'].iloc[0]\n",
    "    print(PlotOne(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobbies = ['biking', 'gardening', 'surfing', 'home design', 'workouts']\n",
    "products = ['face mask', 'bike helmet', 'board shorts', 'back brace', 'puzzles']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can this output be improved?\n",
    "* improve the model and take seasonality into account\n",
    "* make column names more user friendly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "* Step 1: select 4 search term examples; an upward trend, a seasonal, a '2020' spike or dip, and a no trend\n",
    "* Step 2: inspect acf and pacf for each\n",
    "* Step 3: check for seasonality and stationarity\n",
    "* Step 4: select the best model for each\n",
    "* Step 5: Automate this process with OOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting search term examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "upward = GetReport(['mom jeans'])\n",
    "seasonal = GetReport(['sleeping bags'])\n",
    "spike_2020 = GetReport(['face mask'])\n",
    "little_trend = GetReport(['ashtray'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking acf and pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "upward_acf = stattools.acf(upward)\n",
    "seasonal_acf = stattools.acf(seasonal)\n",
    "spike_2020_acf = stattools.acf(spike_2020)\n",
    "little_trend_acf = stattools.acf(little_trend)\n",
    "\n",
    "upward_pacf = stattools.pacf(upward)\n",
    "seasonal_pacf = stattools.pacf(seasonal)\n",
    "spike_2020_pacf = stattools.pacf(spike_2020)\n",
    "little_trend_pacf = stattools.pacf(little_trend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling process\n",
    "## for a given search term\n",
    "\n",
    "1. check for seasonality\n",
    "2. use ARIMA if there is no seasonality, otherwise use SARIMA\n",
    "3. optimize lags programatically, use acf and pacf if nessecary\n",
    "4. evaluate with AIC and BIC\n",
    "\n",
    "helpful reference: https://towardsdatascience.com/time-series-essentials-fe6727ab6a94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
